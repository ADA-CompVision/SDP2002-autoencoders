{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "id": "3CBbVQc0M0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First run this cell in order to get frames of video.\n",
        "# it saves frames into folder names like video name+opencv\n",
        "#after running first cell, please run second cell to see result\n",
        "\n",
        "\n",
        "from datetime import timedelta\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# i.e if video of duration 30 seconds, saves 10 frame per second = 300 frames saved in total\n",
        "SAVING_FRAMES_PER_SECOND = 10\n",
        "\n",
        "def format_timedelta(td):\n",
        "    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05)\n",
        "    omitting microseconds and retaining milliseconds\"\"\"\n",
        "    result = str(td)\n",
        "    try:\n",
        "        result, ms = result.split(\".\")\n",
        "    except ValueError:\n",
        "        return result + \".00\".replace(\":\", \"-\")\n",
        "    ms = int(ms)\n",
        "    ms = round(ms / 1e4)\n",
        "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n",
        "\n",
        "\n",
        "def get_saving_frames_durations(cap, saving_fps):\n",
        "    \"\"\"A function that returns the list of durations where to save the frames\"\"\"\n",
        "    s = []\n",
        "    # get the clip duration by dividing number of frames by the number of frames per second\n",
        "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "    # use np.arange() to make floating-point steps\n",
        "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
        "        s.append(i)\n",
        "    return s\n",
        "\n",
        "\n",
        "def main(video_file,filename):\n",
        "    # make a folder by the name of the video file\n",
        "    if not os.path.isdir(filename):\n",
        "        os.mkdir(filename)\n",
        "    # read the video file\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    # get the FPS of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n",
        "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
        "    # get the list of duration spots to save\n",
        "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
        "    # start the loop\n",
        "    count = 0\n",
        "    while True:\n",
        "        is_read, frame = cap.read()\n",
        "        if not is_read:\n",
        "            # break out of the loop if there are no frames to read\n",
        "            break\n",
        "        # get the duration by dividing the frame count by the FPS\n",
        "        frame_duration = count / fps\n",
        "        try:\n",
        "            # get the earliest duration to save\n",
        "            closest_duration = saving_frames_durations[0]\n",
        "        except IndexError:\n",
        "            # the list is empty, all duration frames were saved\n",
        "            break\n",
        "        if frame_duration >= closest_duration:\n",
        "            # if closest duration is less than or equals the frame duration,\n",
        "            # then save the frame\n",
        "            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
        "            cv2.imwrite(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), frame)\n",
        "            # drop the duration spot from the list, since this duration spot is already saved\n",
        "            try:\n",
        "                saving_frames_durations.pop(0)\n",
        "            except IndexError:\n",
        "                pass\n",
        "        # increment the frame count\n",
        "        count += 1\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    #write your file path here\n",
        "    video_file = \"/content/2022-10-21 19-22-27.mkv\"\n",
        "    filename, _ = os.path.splitext(video_file)\n",
        "    filename += \"-opencv\"\n",
        "    main(video_file,filename)\n"
      ],
      "metadata": {
        "id": "TjkrWRlCM02S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell to see if picture contains hand or not. It can contain both hands\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mediapipe as mp\n",
        "from os import listdir\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_model = mp_hands.Hands(\n",
        "    static_image_mode=True, # only static images\n",
        "    max_num_hands=2, # max 2 hands detection\n",
        "    min_detection_confidence=0.5) # detection confidence\n",
        "    \n",
        "\n",
        "\n",
        "list1=[]\n",
        "folder_dir = filename\n",
        "for image in os.listdir(folder_dir):\n",
        "  if (image.endswith(\".png\") or image.endswith(\".jpg\")\\\n",
        "        or image.endswith(\".jpeg\")):\n",
        "    path=image\n",
        "    if os.path.exists(folder_dir+\"/\"+image):\n",
        "      image = cv2.imread(folder_dir+\"/\"+image)\n",
        "    # now we flip image and convert to rgb image and input to model\n",
        "      image = cv2.flip(image, 1)\n",
        "    \n",
        "      results = mp_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "      print(path,results.multi_handedness,sep=\"      \")\n",
        "    else:\n",
        "        print(\"Empty image\")\n",
        "    \n",
        "\n",
        "#none means no hand\n",
        "# \"label\": Right -> right hand\n",
        "#\"label\": Left-> left hand"
      ],
      "metadata": {
        "id": "JpqPm1noM6S5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}